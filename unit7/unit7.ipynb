{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Unit 7\n",
    "\n",
    "## Part 1: WORD EMBEDDINGS: ENCODING LEXICAL SEMANTICS\n",
    "https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html#sphx-glr-beginner-nlp-word-embeddings-tutorial-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**See tutorial on Website -- Here we provide additional content / Exercise results**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fac60062e90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Robert Guthrie\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Computing Word Embeddings: Continuous Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['We', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study'), (['to', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'a'], 'idea')]\n",
      "\n",
      "Number of training examples: 58\n",
      "vocab_size 49\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".split()\n",
    "\n",
    "# By deriving a set from `raw_text`, we deduplicate the array\n",
    "vocab = set(raw_text)\n",
    "vocab_size = len(vocab)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "def create_context_data(raw_text):\n",
    "\n",
    "    data = []\n",
    "    for i in range(2, len(raw_text) - 2):\n",
    "        context = [raw_text[i - 2], raw_text[i - 1],\n",
    "                   raw_text[i + 1], raw_text[i + 2]]\n",
    "        target = raw_text[i]\n",
    "        data.append((context, target))\n",
    "\n",
    "    print(data[:5])\n",
    "    print(\"\\nNumber of training examples:\", len(data))\n",
    "    print(\"vocab_size\", vocab_size)\n",
    "\n",
    "    return data\n",
    "\n",
    "data = create_context_data(raw_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([39, 19, 32, 30])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_context_vector(context, word_to_ix):\n",
    "    idxs = [word_to_ix[w] for w in context]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "make_context_vector(data[0][0], word_to_ix)  # example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**initial skeleton code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        pass\n",
    "\n",
    "# create your model and train.  here are some functions to help you make\n",
    "# the data ready for use by your module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 50\n",
    "class CBOW(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size *  2 * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "# create your model and train.  here are some functions to help you make\n",
    "# the data ready for use by your module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[225.63277626037598, 222.4949815273285, 219.39596486091614, 216.32562494277954, 213.27869820594788, 210.24801349639893, 207.2434663772583, 204.24631023406982, 201.26555013656616, 198.29729437828064, 195.3220534324646, 192.35428929328918, 189.38395929336548, 186.41633296012878, 183.43802070617676, 180.4414987564087, 177.45058417320251, 174.42366194725037, 171.38644242286682, 168.33168530464172]\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = CBOW(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(20):\n",
    "    total_loss = 0\n",
    "    for context, target in data:\n",
    "                \n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in tensors)\n",
    "        #print(context, target)\n",
    "        context_idxs = make_context_vector(context, word_to_ix)  # example\n",
    "        #print(context_ids)\n",
    "        \n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_idxs)\n",
    "        \n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "print(losses)  # The loss decreased every iteration over the training data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">\n",
    "    \n",
    "### Do some predictions to see if works somehow :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['We', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'computational'], 'idea'), (['the', 'idea', 'computational', 'processes'], 'of')]\n",
      "\n",
      "Number of training examples: 3\n",
      "vocab_size 49\n",
      "[(['We', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'computational'], 'idea'), (['the', 'idea', 'computational', 'processes'], 'of')]\n",
      "['We', 'study', 'idea', 'of'] the\n",
      "['study', 'the', 'of', 'computational'] of\n",
      "['the', 'idea', 'computational', 'processes'] of\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"We study the idea of computational processes\".split()\n",
    "test_data = create_context_data(test_sentence)\n",
    "print(test_data)\n",
    "\n",
    "## we need an idx-to-word\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "ix_to_word = {i: word for word, i in word_to_ix.items()}\n",
    "#print(ix_to_word)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for context, target in test_data:\n",
    "        context_idxs = make_context_vector(context, word_to_ix)  # example\n",
    "        log_probs = model(context_idxs)\n",
    "        \n",
    "        # argmax give the index of the entry with the largest value\n",
    "        pred_idx = log_probs.argmax().item()\n",
    "        print(context, ix_to_word[pred_idx])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ok see it doesn't make too much sense yet, the training data is too small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: LSTM: SEQUENCE MODELS AND LONG-SHORT TERM MEMORY NETWORKS\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html#sphx-glr-beginner-nlp-sequence-models-tutorial-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8}\n"
     ]
    }
   ],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "training_data = [\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]\n",
    "word_to_ix = {}\n",
    "for sent, tags in training_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print(word_to_ix)\n",
    "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n",
    "\n",
    "# These will usually be more like 32 or 64 dimensional.\n",
    "# We will keep them small, so we can see how the weights change as we train.\n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n",
      "tensor([[-0.8667, -1.3783, -1.1158],\n",
      "        [-0.9286, -1.2928, -1.1075],\n",
      "        [-0.9748, -1.3900, -0.9844],\n",
      "        [-0.9014, -1.4633, -1.0147],\n",
      "        [-0.8908, -1.3968, -1.0721]])\n",
      "\n",
      "\n",
      "tensor([[-0.0222, -4.6487, -4.3935],\n",
      "        [-5.9344, -0.0126, -4.6154],\n",
      "        [-3.4598, -3.7630, -0.0562],\n",
      "        [-0.0593, -4.4432, -3.0826],\n",
      "        [-4.0660, -0.0221, -5.3529]])\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# See what the scores are before training\n",
    "# Note that element i,j of the output is the score for tag j for word i.\n",
    "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    print(inputs)\n",
    "    tag_scores = model(inputs)\n",
    "    print(tag_scores)\n",
    "\n",
    "for epoch in range(300):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence, tags in training_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "\n",
    "    # The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
    "    # for word i. The predicted tag is the maximum scoring tag.\n",
    "    # Here, we can see the predicted sequence below is 0 1 2 0 1\n",
    "    # since 0 is index of the maximum value of row 1,\n",
    "    # 1 is the index of maximum value of row 2, etc.\n",
    "    # Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
    "    print(\"\\n\")\n",
    "    print(tag_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Extend with Char-Level features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The dog ate the apple', 'Everybody read that book']\n",
      "['The dog ate the appl', 'Everybody read that boo']\n",
      "Targets ['he dog ate the apple', 'verybody read that book']\n",
      "{'T': 0, 'h': 1, 'e': 2, ' ': 3, 'd': 4, 'o': 5, 'g': 6, 'a': 7, 't': 8, 'p': 9, 'l': 10, 'E': 11, 'v': 12, 'r': 13, 'y': 14, 'b': 15, 'k': 16}\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 3 \n",
    "\n",
    "# 0.) create a list of words in the training texts\n",
    "\n",
    "sentences = [\" \".join(sentence) for sentence, _ in training_data]\n",
    "\n",
    "print(sentences)\n",
    "\n",
    "# create the input and target sequences\n",
    "inputs  = [s[:-1] for s in sentences]\n",
    "targets = [s[1:] for s in sentences]\n",
    "\n",
    "print(inputs)\n",
    "print(\"Targets\", targets)\n",
    "\n",
    "# 1.) create char_to_ix\n",
    "char_to_ix = {}\n",
    "for sentence in sentences:\n",
    "    for c in sentence:\n",
    "        if c not in char_to_ix:\n",
    "            char_to_ix[c] = len(char_to_ix)\n",
    "\n",
    "print(char_to_ix)\n",
    "\n",
    "\n",
    "\n",
    "vocab_size = len(char_to_ix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CharLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
    "        super(CharLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2char = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        char_space = self.hidden2char(lstm_out.view(len(sentence), -1))\n",
    "        char_scores = F.log_softmax(char_space, dim=1)\n",
    "        return char_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The dog ate the appl', 'Everybody read that boo']\n",
      "TTT ['he dog ate the apple', 'verybody read that book']\n",
      "{'T': 0, 'h': 1, 'e': 2, ' ': 3, 'd': 4, 'o': 5, 'g': 6, 'a': 7, 't': 8, 'p': 9, 'l': 10, 'E': 11, 'v': 12, 'r': 13, 'y': 14, 'b': 15, 'k': 16}\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  3,  7,  8,  2,  3,  8,  1,  2,  3,  7,  9,\n",
      "         9, 10])\n",
      "Loss: 2.8664\n",
      "Loss: 2.8985\n",
      "Loss: 2.4864\n",
      "Loss: 2.6731\n",
      "Loss: 2.3867\n",
      "Loss: 2.6116\n",
      "Loss: 2.3293\n",
      "Loss: 2.5545\n",
      "Loss: 2.2521\n",
      "Loss: 2.4790\n",
      "Loss: 2.1230\n",
      "Loss: 2.3779\n",
      "Loss: 1.9631\n",
      "Loss: 2.2354\n",
      "Loss: 1.8024\n",
      "Loss: 2.0601\n",
      "Loss: 1.6451\n",
      "Loss: 1.8818\n",
      "Loss: 1.4764\n",
      "Loss: 1.7065\n",
      "Loss: 1.3133\n",
      "Loss: 1.5217\n",
      "Loss: 1.1706\n",
      "Loss: 1.3549\n",
      "Loss: 1.0379\n",
      "Loss: 1.2176\n",
      "Loss: 0.9172\n",
      "Loss: 1.1011\n",
      "Loss: 0.8114\n",
      "Loss: 1.0052\n",
      "Loss: 0.7239\n",
      "Loss: 0.9162\n",
      "Loss: 0.6461\n",
      "Loss: 0.8249\n",
      "Loss: 0.5725\n",
      "Loss: 0.7426\n",
      "Loss: 0.5149\n",
      "Loss: 0.6867\n",
      "Loss: 0.4767\n",
      "Loss: 0.6418\n",
      "Loss: 0.4234\n",
      "Loss: 0.5963\n",
      "Loss: 0.4026\n",
      "Loss: 0.5661\n",
      "Loss: 0.3627\n",
      "Loss: 0.5304\n",
      "Loss: 0.3446\n",
      "Loss: 0.4992\n",
      "Loss: 0.3132\n",
      "Loss: 0.4811\n",
      "Loss: 0.3170\n",
      "Loss: 0.5681\n",
      "Loss: 0.2741\n",
      "Loss: 0.4277\n",
      "Loss: 0.2629\n",
      "Loss: 0.3989\n",
      "Loss: 0.2472\n",
      "Loss: 0.3903\n",
      "Loss: 0.2370\n",
      "Loss: 0.3648\n",
      "Loss: 0.2246\n",
      "Loss: 0.3495\n",
      "Loss: 0.2135\n",
      "Loss: 0.3371\n",
      "Loss: 0.2068\n",
      "Loss: 0.3390\n",
      "Loss: 0.1956\n",
      "Loss: 0.3160\n",
      "Loss: 0.2344\n",
      "Loss: 0.3616\n",
      "Loss: 0.1803\n",
      "Loss: 0.2971\n",
      "Loss: 0.1753\n",
      "Loss: 0.2793\n",
      "Loss: 0.1735\n",
      "Loss: 0.3016\n",
      "Loss: 0.1677\n",
      "Loss: 0.2644\n",
      "Loss: 0.1599\n",
      "Loss: 0.2758\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  3,  7,  8,  2,  3,  8,  1,  2,  3,  7,  9,\n",
      "         9, 10])\n",
      "\n",
      "\n",
      "tensor([[ -8.6784,  -0.1324,  -3.5342,  -7.6176,  -7.3806,  -3.9603,  -4.8269,\n",
      "          -9.5157,  -6.6154,  -2.9976,  -4.9976,  -8.2922,  -7.6964, -10.8415,\n",
      "          -8.0351,  -5.0305,  -7.0871],\n",
      "        [ -9.4948,  -5.1862,  -0.0350,  -5.5672, -13.1479,  -8.5164,  -8.3765,\n",
      "          -7.8943, -12.5194,  -7.9634,  -8.4175,  -8.6647,  -5.0660,  -8.1811,\n",
      "          -5.1174,  -4.5349, -10.3339],\n",
      "        [-12.3580, -12.2503, -10.7826,  -0.0364,  -6.4471, -14.5751,  -7.2635,\n",
      "          -6.0608, -12.4477, -16.1223, -18.1743, -12.2308, -10.4577,  -3.6926,\n",
      "          -5.2344,  -7.0940, -11.4321],\n",
      "        [ -9.4731,  -8.7065, -11.4684, -10.5925,  -0.1620, -11.2835,  -5.5357,\n",
      "          -6.6075,  -2.9705,  -5.6729, -10.4897, -10.1037,  -8.1690,  -2.7022,\n",
      "          -9.5223,  -3.8317,  -9.5524],\n",
      "        [ -7.4960,  -2.7056,  -3.9942,  -8.6095,  -5.3789,  -0.1469,  -4.2595,\n",
      "          -7.1754,  -5.9840,  -6.9118,  -6.1654,  -7.6475,  -6.2974,  -8.9681,\n",
      "          -4.3808,  -6.1174,  -4.7874],\n",
      "        [ -9.7486,  -2.8231,  -9.0475,  -5.8096,  -2.7483,  -5.7644,  -0.1704,\n",
      "         -10.8218,  -9.1833,  -9.0456, -12.1024,  -9.9128,  -8.7135,  -7.1733,\n",
      "          -3.9188,  -7.1350,  -5.3027],\n",
      "        [-12.1796,  -8.6306, -10.6384,  -0.0276,  -4.8136, -10.1258,  -6.0344,\n",
      "          -4.3402,  -7.8044, -14.5876, -17.1979, -12.5327, -13.7566,  -6.8378,\n",
      "          -6.8918,  -7.0318, -11.1762],\n",
      "        [-10.1287,  -9.9860,  -7.1280,  -7.1884,  -4.6637, -10.7048,  -9.8225,\n",
      "          -0.4373,  -1.4071,  -8.4003, -12.0567, -10.8819, -10.5957,  -4.2790,\n",
      "         -10.3059,  -2.4762, -14.0062],\n",
      "        [-11.3927,  -6.7163, -10.7098, -13.6048,  -3.6522,  -9.6736,  -9.0858,\n",
      "          -6.4484,  -0.0593,  -3.9489,  -9.3117, -12.2164, -13.1615,  -9.2819,\n",
      "         -15.3615,  -4.6944, -13.3793],\n",
      "        [-10.0674,  -4.1417,  -0.0607,  -8.3284, -12.9519,  -7.9061, -10.2950,\n",
      "          -5.8890,  -7.4186,  -5.2376,  -7.2852,  -9.6965,  -8.1949, -10.5118,\n",
      "          -9.6547,  -3.4268, -13.2230],\n",
      "        [-12.6989,  -8.5889,  -7.4937,  -0.0445,  -9.5632, -12.6715, -11.2358,\n",
      "          -3.2937,  -7.1844, -11.1114, -13.8212, -12.4709, -14.1131,  -9.1031,\n",
      "         -11.4220,  -5.3750, -14.9288],\n",
      "        [ -9.9160,  -6.2281,  -7.0651,  -7.6721,  -5.0311, -11.1914, -10.2579,\n",
      "          -3.4526,  -0.3560,  -2.2030,  -7.0026, -10.0644, -10.7513,  -6.9890,\n",
      "         -14.2903,  -1.9271, -13.4027],\n",
      "        [-10.5202,  -0.1104,  -3.5529,  -8.6805, -10.2952,  -6.0509,  -7.0718,\n",
      "         -10.5053,  -7.1631,  -2.7420,  -5.8077, -10.0362, -10.2565, -13.6623,\n",
      "         -11.2825,  -5.5125, -10.2793],\n",
      "        [-11.3086,  -4.0874,  -0.0290,  -5.1304, -15.5862,  -8.0680, -10.4819,\n",
      "          -7.3196, -11.3319,  -8.3853,  -9.2785, -10.5667,  -9.4669, -12.5748,\n",
      "          -8.5605,  -5.4626, -13.2031],\n",
      "        [-13.7858,  -9.4540,  -9.4560,  -0.0272,  -9.0958, -11.9029, -10.4073,\n",
      "          -3.6726,  -8.0207, -14.5182, -16.9588, -13.8881, -16.1447,  -9.9952,\n",
      "         -10.6230,  -7.2464, -14.9517],\n",
      "        [-10.0766,  -8.7097,  -5.6275,  -6.0110,  -6.5109, -11.7434, -11.4933,\n",
      "          -0.6623,  -1.3252,  -5.6584,  -9.5005, -10.3554, -10.4941,  -5.5239,\n",
      "         -12.3818,  -1.5935, -14.8321],\n",
      "        [ -9.9562,  -2.7586,  -5.0252, -12.1795,  -7.5819,  -8.4168,  -8.9483,\n",
      "          -8.0179,  -2.6133,  -0.2126,  -4.7698,  -9.9211,  -9.7318, -10.6449,\n",
      "         -14.0677,  -3.2604, -12.1336],\n",
      "        [ -9.8033,  -2.7987,  -3.2985, -15.5300, -10.8089,  -6.3999, -10.5372,\n",
      "         -10.6254,  -5.3688,  -0.2233,  -2.4299,  -9.4539,  -7.8511, -13.0106,\n",
      "         -13.6605,  -4.9203, -11.1382],\n",
      "        [ -9.6706,  -5.4459,  -5.1280, -18.0415, -11.7035,  -3.8838, -13.2396,\n",
      "         -12.5852,  -7.2820,  -2.0302,  -0.1798,  -9.1028,  -6.7476, -14.8640,\n",
      "         -13.7823,  -8.2029,  -8.7354],\n",
      "        [ -9.7675,  -6.9575,  -0.0328, -13.4471, -15.1961,  -6.6302, -14.0692,\n",
      "          -7.6251,  -8.8294,  -5.2557,  -4.1267,  -9.1977,  -5.9439, -11.8523,\n",
      "         -10.6631,  -5.2526, -12.4946]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = CharLSTM(EMBEDDING_DIM, HIDDEN_DIM, len(char_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "print(inputs)\n",
    "print(\"TTT\", targets)\n",
    "\n",
    "print(char_to_ix)\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs_in = prepare_sequence(inputs[0], char_to_ix)\n",
    "    print(inputs_in)\n",
    "    char_scores = model(inputs_in)\n",
    "\n",
    "                 \n",
    "\n",
    "for epoch in range(2000):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for i in range(len(inputs)):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        sent_in = prepare_sequence(inputs[i], char_to_ix)\n",
    "        targets_in = prepare_sequence(targets[i], char_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        char_scores = model(sent_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(char_scores, targets_in)\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        if epoch%50 == 0:\n",
    "        #print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "            print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "\n",
    "# See what the scores are after training\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs_in = prepare_sequence(inputs[0], char_to_ix)\n",
    "    print(inputs_in)\n",
    "    char_scores = model(inputs_in)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(char_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
